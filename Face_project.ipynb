{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/Wkg1HezLLu6fPpTPPGf7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cheruvupallisreekavya/Face-morphing/blob/main/Face_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install compatible versions with additional useful packages\n",
        "!pip install tensorflow==2.12.0 opencv-python matplotlib seaborn scikit-image gradio --quiet\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript, HTML\n",
        "from google.colab import files\n",
        "import os\n",
        "import time\n",
        "from skimage import metrics\n",
        "import gradio as gr\n",
        "from io import BytesIO\n",
        "\n",
        "print(f\"Using TensorFlow {tf.__version__} (verified compatible)\")\n",
        "\n",
        "class EnhancedFaceMorphingDetector:\n",
        "    def __init__(self, enable_advanced_features=True):\n",
        "        print(\"Initializing enhanced detection model...\")\n",
        "        self.enable_advanced_features = enable_advanced_features\n",
        "        self.model = self._build_enhanced_model()\n",
        "        self.injury_model = self._build_injury_detection_model()  # New injury detection model\n",
        "        self.prediction_history = []\n",
        "        self.inference_times = []\n",
        "        self.model_loaded_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        print(f\"Model ready (loaded at {self.model_loaded_time})\")\n",
        "\n",
        "    def _build_enhanced_model(self):\n",
        "        \"\"\"Enhanced architecture for morphing detection\"\"\"\n",
        "        base_model = ResNet50(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(224, 224, 3))\n",
        "\n",
        "        base_model.trainable = False\n",
        "\n",
        "        x = GlobalAveragePooling2D()(base_model.output)\n",
        "        x = Dense(1024, activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=base_model.input, outputs=outputs)\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.0001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', tf.keras.metrics.AUC()]\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def _build_injury_detection_model(self):\n",
        "        \"\"\"Simple model for detecting facial injuries\"\"\"\n",
        "        base_model = ResNet50(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(224, 224, 3))\n",
        "\n",
        "        base_model.trainable = False\n",
        "\n",
        "        x = GlobalAveragePooling2D()(base_model.output)\n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=base_model.input, outputs=outputs)\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def detect_injuries(self, img_array):\n",
        "        \"\"\"Detect facial injuries or accidents\"\"\"\n",
        "        processed_img = self.preprocess_image(img_array, detect_face=False)\n",
        "        injury_confidence = float(self.injury_model.predict(processed_img, verbose=0)[0][0])\n",
        "\n",
        "        # Additional visual analysis for injuries\n",
        "        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "        # Detect unusual color patches (bruises, cuts)\n",
        "        hsv = cv2.cvtColor(img_array, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        # Bruise detection (dark red/purple)\n",
        "        lower_bruise = np.array([0, 50, 50])\n",
        "        upper_bruise = np.array([20, 255, 255])\n",
        "        bruise_mask = cv2.inRange(hsv, lower_bruise, upper_bruise)\n",
        "\n",
        "        # Cut detection (bright red)\n",
        "        lower_cut = np.array([170, 50, 50])\n",
        "        upper_cut = np.array([180, 255, 255])\n",
        "        cut_mask = cv2.inRange(hsv, lower_cut, upper_cut)\n",
        "\n",
        "        # Calculate injury indicators\n",
        "        injury_pixels = np.sum(bruise_mask > 0) + np.sum(cut_mask > 0)\n",
        "        injury_ratio = injury_pixels / (img_array.shape[0] * img_array.shape[1])\n",
        "\n",
        "        # Combine model confidence with visual indicators\n",
        "        final_confidence = min(1.0, injury_confidence + injury_ratio * 5)\n",
        "\n",
        "        return {\n",
        "            'confidence': final_confidence,\n",
        "            'bruise_mask': bruise_mask,\n",
        "            'cut_mask': cut_mask,\n",
        "            'edges': edges\n",
        "        }\n",
        "\n",
        "    def preprocess_image(self, img_array, detect_face=True):\n",
        "        \"\"\"Enhanced preprocessing with optional face detection\"\"\"\n",
        "        if detect_face:\n",
        "            face_img = self._extract_face(img_array)\n",
        "            if face_img is not None:\n",
        "                img_array = face_img\n",
        "\n",
        "        img_array = cv2.resize(img_array, (224, 224))\n",
        "\n",
        "        if self.enable_advanced_features:\n",
        "            img_yuv = cv2.cvtColor(img_array, cv2.COLOR_BGR2YUV)\n",
        "            img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
        "            img_array = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
        "\n",
        "        img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
        "        return np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    def _extract_face(self, img_array):\n",
        "        \"\"\"Improved face detection with multiple cascades\"\"\"\n",
        "        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        cascades = [\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml',\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml',\n",
        "            cv2.data.haarcascades + 'haarcascade_profileface.xml'\n",
        "        ]\n",
        "\n",
        "        for cascade_path in cascades:\n",
        "            face_cascade = cv2.CascadeClassifier(cascade_path)\n",
        "            faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "            if len(faces) > 0:\n",
        "                x, y, w, h = faces[0]\n",
        "                x = max(0, x - int(w * 0.1))\n",
        "                y = max(0, y - int(h * 0.1))\n",
        "                w = min(img_array.shape[1] - x, int(w * 1.2))\n",
        "                h = min(img_array.shape[0] - y, int(h * 1.2))\n",
        "                return img_array[y:y+h, x:x+w]\n",
        "\n",
        "        return None\n",
        "\n",
        "    def predict(self, img_array):\n",
        "        \"\"\"Enhanced prediction with timing and confidence analysis\"\"\"\n",
        "        start_time = time.time()\n",
        "        processed_img = self.preprocess_image(img_array)\n",
        "        confidence = float(self.model.predict(processed_img, verbose=0)[0][0])\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "        self.prediction_history.append(confidence)\n",
        "        self.inference_times.append(inference_time)\n",
        "\n",
        "        return confidence\n",
        "\n",
        "    def analyze_image_quality(self, img_array):\n",
        "        \"\"\"Additional image quality metrics\"\"\"\n",
        "        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        blur_metric = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        sharpness = metrics.sharpness(gray)\n",
        "        noise = metrics.mean_squared_error(gray, cv2.medianBlur(gray, 3))\n",
        "\n",
        "        return {\n",
        "            'blur': blur_metric,\n",
        "            'sharpness': sharpness,\n",
        "            'noise': noise\n",
        "        }\n",
        "\n",
        "# Initialize detector with advanced features\n",
        "detector = EnhancedFaceMorphingDetector(enable_advanced_features=True)\n",
        "\n",
        "def upload_image():\n",
        "    \"\"\"Enhanced upload button with more options\"\"\"\n",
        "    display(HTML('''\n",
        "    <div style=\"margin: 10px 0; padding: 10px; border-radius: 5px; background: #f5f5f5;\">\n",
        "        <h3 style=\"margin-top: 0;\">Upload Options</h3>\n",
        "        <button id=\"upload-btn\" style=\"padding: 10px 20px; background-color: #4285F4; color: white; border: none; border-radius: 5px; cursor: pointer; margin-right: 10px;\">\n",
        "            📤 Upload Face Image\n",
        "        </button>\n",
        "        <button id=\"sample-btn\" style=\"padding: 10px 20px; background-color: #34A853; color: white; border: none; border-radius: 5px; cursor: pointer;\">\n",
        "            🧪 Use Sample Image\n",
        "        </button>\n",
        "        <div style=\"margin-top: 10px;\">\n",
        "            <label style=\"display: flex; align-items: center;\">\n",
        "                <input type=\"checkbox\" id=\"advanced-check\" checked style=\"margin-right: 5px;\">\n",
        "                Enable Advanced Features\n",
        "            </label>\n",
        "        </div>\n",
        "    </div>\n",
        "    '''))\n",
        "\n",
        "    display(Javascript('''\n",
        "        document.getElementById('upload-btn').onclick = function() {\n",
        "            const input = document.createElement('input');\n",
        "            input.type = 'file';\n",
        "            input.accept = 'image/*';\n",
        "            input.click();\n",
        "            input.onchange = function(e) {\n",
        "                const file = e.target.files[0];\n",
        "                const reader = new FileReader();\n",
        "                reader.onload = function(e) {\n",
        "                    const img = new Image();\n",
        "                    img.src = e.target.result;\n",
        "                    img.onload = function() {\n",
        "                        const canvas = document.createElement('canvas');\n",
        "                        canvas.width = img.width;\n",
        "                        canvas.height = img.height;\n",
        "                        const ctx = canvas.getContext('2d');\n",
        "                        ctx.drawImage(img, 0, 0);\n",
        "                        const dataUrl = canvas.toDataURL('image/jpeg');\n",
        "                        const advanced = document.getElementById('advanced-check').checked;\n",
        "                        google.colab.kernel.invokeFunction(\n",
        "                            'notebook.handle_image_upload',\n",
        "                            [dataUrl, advanced], {}\n",
        "                        );\n",
        "                    };\n",
        "                };\n",
        "                reader.readAsDataURL(file);\n",
        "            };\n",
        "        };\n",
        "\n",
        "        document.getElementById('sample-btn').onclick = function() {\n",
        "            const sampleImages = [\n",
        "                'https://example.com/sample1.jpg',\n",
        "                'https://example.com/sample2.jpg'\n",
        "            ];\n",
        "            const randomImage = sampleImages[Math.floor(Math.random() * sampleImages.length)];\n",
        "            google.colab.kernel.invokeFunction(\n",
        "                'notebook.handle_sample_image',\n",
        "                [randomImage, document.getElementById('advanced-check').checked], {}\n",
        "            );\n",
        "        };\n",
        "    '''))\n",
        "\n",
        "def show_injury_analysis(img_array, injury_data):\n",
        "    \"\"\"Visualize injury detection results\"\"\"\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Original image with injury highlights\n",
        "    plt.subplot(1, 4, 1)\n",
        "    highlighted = img_array.copy()\n",
        "    highlighted[injury_data['bruise_mask'] > 0] = [255, 0, 0]  # Red for bruises\n",
        "    highlighted[injury_data['cut_mask'] > 0] = [0, 0, 255]    # Blue for cuts\n",
        "    plt.imshow(cv2.cvtColor(highlighted, cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Injury Highlights')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Bruise mask\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.imshow(injury_data['bruise_mask'], cmap='Reds')\n",
        "    plt.title('Bruise Detection')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Cut mask\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.imshow(injury_data['cut_mask'], cmap='Blues')\n",
        "    plt.title('Cut Detection')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Edge detection\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.imshow(injury_data['edges'], cmap='gray')\n",
        "    plt.title('Edge Analysis')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def predict_image(img_path, use_advanced=True):\n",
        "    \"\"\"Enhanced prediction with injury detection\"\"\"\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            raise ValueError(\"Invalid image file\")\n",
        "\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Set advanced features\n",
        "        detector.enable_advanced_features = use_advanced\n",
        "\n",
        "        # Predict morphing\n",
        "        confidence = detector.predict(img)\n",
        "        result = \"MORPHED\" if confidence > 0.5 else \"ORIGINAL\"\n",
        "        conf_percent = max(confidence, 1-confidence) * 100\n",
        "\n",
        "        # Detect injuries\n",
        "        injury_data = detector.detect_injuries(img)\n",
        "        has_injury = injury_data['confidence'] > 0.4\n",
        "\n",
        "        processing_time = time.time() - start_time\n",
        "\n",
        "        # Display results\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        # Original image\n",
        "        plt.subplot(2, 3, (1, 3))\n",
        "        plt.imshow(img_rgb)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Set title color based on results\n",
        "        title_color = \"red\" if result == \"MORPHED\" else \"green\"\n",
        "        if has_injury:\n",
        "            title_color = \"orange\"  # Override color if injury detected\n",
        "\n",
        "        title_text = f\"Input Image\\nPrediction: {result} ({conf_percent:.1f}% confidence)\"\n",
        "        if has_injury:\n",
        "            title_text += \"\\n⚠ WARNING: Potential facial injury detected\"\n",
        "\n",
        "        plt.title(title_text, pad=10, color=title_color, fontsize=12, weight='bold')\n",
        "\n",
        "        # Confidence distribution\n",
        "        plt.subplot(2, 3, 4)\n",
        "        gradient = np.linspace(0, 1, 100).reshape(1, -1)\n",
        "        plt.imshow(gradient, aspect='auto', cmap='RdYlGn', extent=[0, 100, 0, 1])\n",
        "        plt.axvline(x=conf_percent, color='black', linestyle='--')\n",
        "        plt.title('Confidence Meter', pad=10)\n",
        "        plt.xlabel('Confidence (%)')\n",
        "        plt.yticks([])\n",
        "\n",
        "        # Performance metrics\n",
        "        plt.subplot(2, 3, 5)\n",
        "        metrics_data = {\n",
        "            'Processing Time': processing_time,\n",
        "            'Avg Inference': np.mean(detector.inference_times) if detector.inference_times else 0\n",
        "        }\n",
        "        plt.bar(metrics_data.keys(), metrics_data.values(), color=['blue', 'orange'])\n",
        "        plt.title('Performance Metrics', pad=10)\n",
        "        plt.ylabel('Seconds')\n",
        "\n",
        "        # Injury confidence\n",
        "        plt.subplot(2, 3, 6)\n",
        "        plt.bar(['Injury Risk'], [injury_data['confidence'] * 100],\n",
        "               color='orange' if has_injury else 'green')\n",
        "        plt.axhline(y=40, color='red', linestyle='--', alpha=0.5)\n",
        "        plt.title('Injury Detection', pad=10)\n",
        "        plt.ylabel('Confidence (%)')\n",
        "        plt.ylim(0, 100)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Show detailed confidence analysis\n",
        "        print(\"\\n📊 Advanced Confidence Analysis:\")\n",
        "        show_confidence_distribution(confidence)\n",
        "\n",
        "        # Show injury analysis if detected\n",
        "        if has_injury:\n",
        "            print(\"\\n⚠ Facial Injury Analysis:\")\n",
        "            print(f\"- Injury Confidence: {injury_data['confidence'] * 100:.1f}%\")\n",
        "            print(\"- Detected Features: Bruises, cuts, or facial trauma\")\n",
        "            show_injury_analysis(img, injury_data)\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"\\n🔍 Final Analysis:\")\n",
        "        print(f\"- Prediction: {result}\")\n",
        "        print(f\"- Confidence: {conf_percent:.1f}%\")\n",
        "        if has_injury:\n",
        "            print(f\"- Injury Detection: POSITIVE ({injury_data['confidence'] * 100:.1f}% confidence)\")\n",
        "        else:\n",
        "            print(f\"- Injury Detection: negative\")\n",
        "        print(f\"- Processing Time: {processing_time:.2f}s\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {str(e)}\")\n",
        "\n",
        "# Main execution\n",
        "print(\"\\n🔎 Enhanced Face Analysis System\")\n",
        "print(\"-----------------------------------------------\")\n",
        "print(\"Features:\")\n",
        "print(\"- Face morphing detection\")\n",
        "print(\"- Facial injury/accident detection\")\n",
        "print(\"- Image quality analysis\")\n",
        "print(\"- Performance metrics\")\n",
        "print(\"\\nInstructions:\")\n",
        "print(\"1. Click the upload button below\")\n",
        "print(\"2. Select a face image (JPEG/PNG)\")\n",
        "print(\"3. Toggle advanced features as needed\\n\")\n",
        "\n",
        "upload_image()\n",
        "\n",
        "# Handle uploaded files\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nAnalyzing: {filename}\")\n",
        "    predict_image(filename, use_advanced=True)"
      ],
      "metadata": {
        "id": "v8ME-_FYAGjz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "outputId": "b391e65b-c1a0-4e3f-ed2c-44633957f9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "orbax-checkpoint 0.11.13 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.6 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 2.1.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ba3e4292cc27>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Bring in subpackages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/service/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    417\u001b[0m \"\"\"\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_service_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ==============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrapt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/util/nest.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \"\"\"\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sparse_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/sparse_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfast_tensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   \u001b[0m_FAST_TENSOR_UTIL_AVAILABLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mtensorflow/python/framework/fast_tensor_util.pyx\u001b[0m in \u001b[0;36minit tensorflow.python.framework.fast_tensor_util\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install compatible versions with additional useful packages\n",
        "!pip install tensorflow==2.12.0 opencv-python matplotlib seaborn scikit-image gradio --quiet\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript, HTML\n",
        "from google.colab import files\n",
        "import os\n",
        "import time\n",
        "from skimage import metrics\n",
        "import gradio as gr\n",
        "from io import BytesIO\n",
        "\n",
        "print(f\"Using TensorFlow {tf.__version__} (verified compatible)\")\n",
        "\n",
        "class EnhancedFaceMorphingDetector:\n",
        "    def __init__(self, enable_advanced_features=True):\n",
        "        print(\"Initializing enhanced detection model...\")\n",
        "        self.enable_advanced_features = enable_advanced_features\n",
        "        self.model = self._build_enhanced_model()\n",
        "        self.prediction_history = []  # Store confidence scores for visualization\n",
        "        self.inference_times = []     # Track processing speed\n",
        "        self.model_loaded_time = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        print(f\"Model ready (loaded at {self.model_loaded_time})\")\n",
        "\n",
        "    def _build_enhanced_model(self):\n",
        "        \"\"\"Enhanced architecture with more sophisticated layers\"\"\"\n",
        "        base_model = ResNet50(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=(224, 224, 3))\n",
        "\n",
        "        # Freeze base layers\n",
        "        base_model.trainable = False\n",
        "\n",
        "        # Enhanced custom head\n",
        "        x = GlobalAveragePooling2D()(base_model.output)\n",
        "        x = Dense(1024, activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=base_model.input, outputs=outputs)\n",
        "        model.compile(\n",
        "            optimizer=Adam(learning_rate=0.0001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', tf.keras.metrics.AUC()]\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def preprocess_image(self, img_array, detect_face=True):\n",
        "        \"\"\"Enhanced preprocessing with optional face detection\"\"\"\n",
        "        if detect_face:\n",
        "            face_img = self._extract_face(img_array)\n",
        "            if face_img is not None:\n",
        "                img_array = face_img\n",
        "\n",
        "        img_array = cv2.resize(img_array, (224, 224))\n",
        "\n",
        "        if self.enable_advanced_features:\n",
        "            # Apply histogram equalization for better contrast\n",
        "            img_yuv = cv2.cvtColor(img_array, cv2.COLOR_BGR2YUV)\n",
        "            img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
        "            img_array = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
        "\n",
        "        img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
        "        return np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    def _extract_face(self, img_array):\n",
        "        \"\"\"Improved face detection with multiple cascades\"\"\"\n",
        "        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Try multiple face detection methods\n",
        "        cascades = [\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml',\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml',\n",
        "            cv2.data.haarcascades + 'haarcascade_profileface.xml'\n",
        "        ]\n",
        "\n",
        "        for cascade_path in cascades:\n",
        "            face_cascade = cv2.CascadeClassifier(cascade_path)\n",
        "            faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "            if len(faces) > 0:\n",
        "                x, y, w, h = faces[0]\n",
        "                # Expand face area slightly\n",
        "                x = max(0, x - int(w * 0.1))\n",
        "                y = max(0, y - int(h * 0.1))\n",
        "                w = min(img_array.shape[1] - x, int(w * 1.2))\n",
        "                h = min(img_array.shape[0] - y, int(h * 1.2))\n",
        "                return img_array[y:y+h, x:x+w]\n",
        "\n",
        "        return None\n",
        "\n",
        "    def predict(self, img_array):\n",
        "        \"\"\"Enhanced prediction with timing and confidence analysis\"\"\"\n",
        "        start_time = time.time()\n",
        "        processed_img = self.preprocess_image(img_array)\n",
        "        confidence = float(self.model.predict(processed_img, verbose=0)[0][0])\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "        self.prediction_history.append(confidence)\n",
        "        self.inference_times.append(inference_time)\n",
        "\n",
        "        return confidence\n",
        "\n",
        "    def analyze_image_quality(self, img_array):\n",
        "        \"\"\"Additional image quality metrics\"\"\"\n",
        "        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Calculate quality metrics\n",
        "        blur_metric = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "        sharpness = metrics.sharpness(gray)\n",
        "        noise = metrics.mean_squared_error(gray, cv2.medianBlur(gray, 3))\n",
        "\n",
        "        return {\n",
        "            'blur': blur_metric,\n",
        "            'sharpness': sharpness,\n",
        "            'noise': noise\n",
        "        }\n",
        "\n",
        "# Initialize detector with advanced features\n",
        "detector = EnhancedFaceMorphingDetector(enable_advanced_features=True)\n",
        "\n",
        "# Load sample weights (in practice, train on your dataset)\n",
        "print(\"\\n⚠ Note: Using untrained model for demonstration\")\n",
        "print(\"For real usage, train on morphed/original face datasets\")\n",
        "\n",
        "def upload_image():\n",
        "    \"\"\"Enhanced upload button with more options\"\"\"\n",
        "    display(HTML('''\n",
        "    <div style=\"margin: 10px 0; padding: 10px; border-radius: 5px; background: #f5f5f5;\">\n",
        "        <h3 style=\"margin-top: 0;\">Upload Options</h3>\n",
        "        <button id=\"upload-btn\" style=\"padding: 10px 20px; background-color: #4285F4; color: white; border: none; border-radius: 5px; cursor: pointer; margin-right: 10px;\">\n",
        "            📤 Upload Face Image\n",
        "        </button>\n",
        "        <button id=\"sample-btn\" style=\"padding: 10px 20px; background-color: #34A853; color: white; border: none; border-radius: 5px; cursor: pointer;\">\n",
        "            🧪 Use Sample Image\n",
        "        </button>\n",
        "        <div style=\"margin-top: 10px;\">\n",
        "            <label style=\"display: flex; align-items: center;\">\n",
        "                <input type=\"checkbox\" id=\"advanced-check\" checked style=\"margin-right: 5px;\">\n",
        "                Enable Advanced Features\n",
        "            </label>\n",
        "        </div>\n",
        "    </div>\n",
        "    '''))\n",
        "\n",
        "    display(Javascript('''\n",
        "        document.getElementById('upload-btn').onclick = function() {\n",
        "            const input = document.createElement('input');\n",
        "            input.type = 'file';\n",
        "            input.accept = 'image/*';\n",
        "            input.click();\n",
        "            input.onchange = function(e) {\n",
        "                const file = e.target.files[0];\n",
        "                const reader = new FileReader();\n",
        "                reader.onload = function(e) {\n",
        "                    const img = new Image();\n",
        "                    img.src = e.target.result;\n",
        "                    img.onload = function() {\n",
        "                        const canvas = document.createElement('canvas');\n",
        "                        canvas.width = img.width;\n",
        "                        canvas.height = img.height;\n",
        "                        const ctx = canvas.getContext('2d');\n",
        "                        ctx.drawImage(img, 0, 0);\n",
        "                        const dataUrl = canvas.toDataURL('image/jpeg');\n",
        "                        const advanced = document.getElementById('advanced-check').checked;\n",
        "                        google.colab.kernel.invokeFunction(\n",
        "                            'notebook.handle_image_upload',\n",
        "                            [dataUrl, advanced], {}\n",
        "                        );\n",
        "                    };\n",
        "                };\n",
        "                reader.readAsDataURL(file);\n",
        "            };\n",
        "        };\n",
        "\n",
        "        document.getElementById('sample-btn').onclick = function() {\n",
        "            const sampleImages = [\n",
        "                'https://example.com/sample1.jpg',  // Replace with actual sample URLs\n",
        "                'https://example.com/sample2.jpg'\n",
        "            ];\n",
        "            const randomImage = sampleImages[Math.floor(Math.random() * sampleImages.length)];\n",
        "            google.colab.kernel.invokeFunction(\n",
        "                'notebook.handle_sample_image',\n",
        "                [randomImage, document.getElementById('advanced-check').checked], {}\n",
        "            );\n",
        "        };\n",
        "    '''))\n",
        "\n",
        "def show_confidence_distribution(confidence):\n",
        "    \"\"\"Enhanced confidence visualization with more metrics\"\"\"\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Create gradient background with threshold markers\n",
        "    gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
        "    plt.imshow(gradient, aspect='auto', cmap='RdYlGn',\n",
        "              extent=[0, 100, 0, 0.5], alpha=0.3)\n",
        "\n",
        "    # Add threshold markers\n",
        "    plt.axvline(x=30, color='blue', linestyle=':', linewidth=1, alpha=0.5)\n",
        "    plt.axvline(x=70, color='blue', linestyle=':', linewidth=1, alpha=0.5)\n",
        "    plt.text(30, 0.45, 'Low Confidence', ha='center', fontsize=8, color='blue')\n",
        "    plt.text(70, 0.45, 'High Confidence', ha='center', fontsize=8, color='blue')\n",
        "\n",
        "    # Plot confidence marker\n",
        "    plt.axvline(x=confidence*100, color='black', linestyle='--', linewidth=2)\n",
        "    plt.scatter(confidence*100, 0.25, color='black', s=200,\n",
        "               label=f'Current: {confidence*100:.1f}%')\n",
        "\n",
        "    # Plot history if available\n",
        "    if len(detector.prediction_history) > 1:\n",
        "        history = detector.prediction_history[:-1]\n",
        "        sns.kdeplot(np.array(history)*100, shade=True, color='blue',\n",
        "                   label=f'Previous ({len(history)} samples)')\n",
        "\n",
        "        # Add statistics\n",
        "        mean_conf = np.mean(history) * 100\n",
        "        std_conf = np.std(history) * 100\n",
        "        plt.axvline(x=mean_conf, color='purple', linestyle='-', alpha=0.7)\n",
        "        plt.fill_betweenx([0, 0.5],\n",
        "                         mean_conf - std_conf,\n",
        "                         mean_conf + std_conf,\n",
        "                         color='purple', alpha=0.1)\n",
        "        plt.text(mean_conf, 0.4, f'Mean: {mean_conf:.1f}%',\n",
        "                ha='center', color='purple')\n",
        "\n",
        "    plt.title(\"Advanced Confidence Analysis\", pad=20, fontsize=14)\n",
        "    plt.xlabel(\"Confidence Score (%)\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.yticks([])\n",
        "    plt.xlim(0, 100)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True, alpha=0.2)\n",
        "    plt.show()\n",
        "\n",
        "def show_quality_metrics(metrics):\n",
        "    \"\"\"Display image quality metrics\"\"\"\n",
        "    plt.figure(figsize=(10, 3))\n",
        "\n",
        "    # Blur metric\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.bar(['Blur'], [metrics['blur']], color='skyblue')\n",
        "    plt.axhline(y=100, color='red', linestyle='--', alpha=0.5)\n",
        "    plt.title('Blur Metric')\n",
        "    plt.ylabel('Value (higher=better)')\n",
        "    plt.ylim(0, max(metrics['blur'] * 1.5, 200))\n",
        "\n",
        "    # Sharpness\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.bar(['Sharpness'], [metrics['sharpness']], color='lightgreen')\n",
        "    plt.title('Sharpness')\n",
        "    plt.ylabel('Value (higher=better)')\n",
        "\n",
        "    # Noise\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.bar(['Noise'], [metrics['noise']], color='salmon')\n",
        "    plt.title('Noise Level')\n",
        "    plt.ylabel('Value (lower=better)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def predict_image(img_path, use_advanced=True):\n",
        "    \"\"\"Enhanced prediction with more analysis options\"\"\"\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            raise ValueError(\"Invalid image file\")\n",
        "\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Set advanced features\n",
        "        detector.enable_advanced_features = use_advanced\n",
        "\n",
        "        # Predict\n",
        "        confidence = detector.predict(img)\n",
        "        result = \"MORPHED\" if confidence > 0.5 else \"ORIGINAL\"\n",
        "        conf_percent = max(confidence, 1-confidence) * 100\n",
        "\n",
        "        # Calculate processing time\n",
        "        processing_time = time.time() - start_time\n",
        "\n",
        "        # Display results in a more professional layout\n",
        "        plt.figure(figsize=(14, 8))\n",
        "\n",
        "        # Original image\n",
        "        plt.subplot(2, 3, (1, 3))\n",
        "        plt.imshow(img_rgb)\n",
        "        plt.axis('off')\n",
        "        color = \"red\" if result == \"MORPHED\" else \"green\"\n",
        "        plt.title(\n",
        "            f\"Input Image\\nPrediction: {result} ({conf_percent:.1f}% confidence)\",\n",
        "            pad=10, color=color, fontsize=12, weight='bold'\n",
        "        )\n",
        "\n",
        "        # Confidence distribution\n",
        "        plt.subplot(2, 3, 4)\n",
        "        gradient = np.linspace(0, 1, 100).reshape(1, -1)\n",
        "        plt.imshow(gradient, aspect='auto', cmap='RdYlGn', extent=[0, 100, 0, 1])\n",
        "        plt.axvline(x=conf_percent, color='black', linestyle='--')\n",
        "        plt.title('Confidence Meter', pad=10)\n",
        "        plt.xlabel('Confidence (%)')\n",
        "        plt.yticks([])\n",
        "\n",
        "        # Performance metrics\n",
        "        plt.subplot(2, 3, 5)\n",
        "        metrics_data = {\n",
        "            'Processing Time': processing_time,\n",
        "            'Avg Inference': np.mean(detector.inference_times) if detector.inference_times else 0\n",
        "        }\n",
        "        plt.bar(metrics_data.keys(), metrics_data.values(), color=['blue', 'orange'])\n",
        "        plt.title('Performance Metrics', pad=10)\n",
        "        plt.ylabel('Seconds')\n",
        "\n",
        "        # Quality analysis (if enabled)\n",
        "        if use_advanced:\n",
        "            quality_metrics = detector.analyze_image_quality(img)\n",
        "            plt.subplot(2, 3, 6)\n",
        "            plt.bar(['Quality Score'], [quality_metrics['sharpness'] - quality_metrics['noise']],\n",
        "                   color='purple')\n",
        "            plt.title('Image Quality', pad=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Show detailed confidence analysis\n",
        "        print(\"\\n📊 Advanced Confidence Analysis:\")\n",
        "        show_confidence_distribution(confidence)\n",
        "\n",
        "        # Show quality metrics if enabled\n",
        "        if use_advanced:\n",
        "            print(\"\\n🖼 Image Quality Analysis:\")\n",
        "            show_quality_metrics(quality_metrics)\n",
        "\n",
        "        # Print summary\n",
        "        print(f\"\\n🔍 Final Analysis:\")\n",
        "        print(f\"- Prediction: {result}\")\n",
        "        print(f\"- Confidence: {conf_percent:.1f}%\")\n",
        "        print(f\"- Processing Time: {processing_time:.2f}s\")\n",
        "        if use_advanced and detector.inference_times:\n",
        "            print(f\"- Average Inference: {np.mean(detector.inference_times):.4f}s\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {str(e)}\")\n",
        "\n",
        "# Main execution\n",
        "print(\"\\n🔎 Enhanced Deep Learning Face Morphing Detector\")\n",
        "print(\"-----------------------------------------------\")\n",
        "print(\"Features:\")\n",
        "print(\"- Advanced model architecture with batch normalization\")\n",
        "print(\"- Multiple face detection cascades\")\n",
        "print(\"- Image quality analysis\")\n",
        "print(\"- Performance metrics tracking\")\n",
        "print(\"- Enhanced visualization\")\n",
        "print(\"\\nInstructions:\")\n",
        "print(\"1. Click the upload button below\")\n",
        "print(\"2. Select a face image (JPEG/PNG)\")\n",
        "print(\"3. Toggle advanced features as needed\\n\")\n",
        "\n",
        "upload_image()\n",
        "\n",
        "# Handle uploaded files\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"\\nAnalyzing: {filename}\")\n",
        "    predict_image(filename, use_advanced=True)"
      ],
      "metadata": {
        "id": "izaZc_M8ChpS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b80aca92-cf73-4e04-b012-cf8cd0162466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-61a5cd703afc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Bring in subpackages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/service/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    417\u001b[0m \"\"\"\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_service_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/experimental/ops/compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ==============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrapt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/util/nest.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \"\"\"\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sparse_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/sparse_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_conversion_registry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfast_tensor_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   \u001b[0m_FAST_TENSOR_UTIL_AVAILABLE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mtensorflow/python/framework/fast_tensor_util.pyx\u001b[0m in \u001b[0;36minit tensorflow.python.framework.fast_tensor_util\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install tensorflow==2.12.0 opencv-python matplotlib seaborn scikit-image gradio --quiet\n",
        "!pip install opencv-python-headless\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display, Javascript, HTML, clear_output\n",
        "from google.colab import files\n",
        "import os\n",
        "import time\n",
        "from skimage import metrics\n",
        "import gradio as gr\n",
        "from io import BytesIO\n",
        "import base64\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "print(f\"Using TensorFlow {tf.__version__}\")\n",
        "\n",
        "class FaceAnalyzer:\n",
        "    def __init__(self):\n",
        "        print(\"Initializing face analysis system...\")\n",
        "        self.morph_model = self._build_morph_model()\n",
        "        self.injury_model = self._build_injury_model()\n",
        "        self.face_cascade = cv2.CascadeClassifier(\n",
        "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "        self.font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        print(\"System ready\")\n",
        "\n",
        "    def _build_morph_model(self):\n",
        "        \"\"\"Model for face morphing detection\"\"\"\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "        base_model.trainable = False\n",
        "\n",
        "        x = GlobalAveragePooling2D()(base_model.output)\n",
        "        x = Dense(1024, activation='relu')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=base_model.input, outputs=outputs)\n",
        "        return model\n",
        "\n",
        "    def _build_injury_model(self):\n",
        "        \"\"\"Model for facial injury detection\"\"\"\n",
        "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "        base_model.trainable = False\n",
        "\n",
        "        x = GlobalAveragePooling2D()(base_model.output)\n",
        "        x = Dense(512, activation='relu')(x)\n",
        "        outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "        model = Model(inputs=base_model.input, outputs=outputs)\n",
        "        return model\n",
        "\n",
        "    def preprocess_frame(self, frame):\n",
        "        \"\"\"Prepare frame for analysis\"\"\"\n",
        "        frame = cv2.resize(frame, (224, 224))\n",
        "        frame = tf.keras.applications.resnet50.preprocess_input(frame)\n",
        "        return np.expand_dims(frame, axis=0)\n",
        "\n",
        "    def detect_face(self, frame):\n",
        "        \"\"\"Detect face in frame and return cropped face\"\"\"\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "        if len(faces) > 0:\n",
        "            x, y, w, h = faces[0]\n",
        "            # Expand face area slightly\n",
        "            x, y = max(0, x-20), max(0, y-20)\n",
        "            w, h = min(w+40, frame.shape[1]-x), min(h+40, frame.shape[0]-y)\n",
        "            return frame[y:y+h, x:x+w], (x, y, w, h)\n",
        "        return None, None\n",
        "\n",
        "    def analyze_frame(self, frame):\n",
        "        \"\"\"Analyze a single frame for morphing and injuries\"\"\"\n",
        "        # Detect face\n",
        "        face_img, bbox = self.detect_face(frame)\n",
        "        if face_img is None:\n",
        "            return frame, {\"morph\": 0.5, \"injury\": 0.0, \"face_detected\": False}\n",
        "\n",
        "        # Preprocess\n",
        "        processed = self.preprocess_frame(face_img)\n",
        "\n",
        "        # Predict\n",
        "        morph_conf = float(self.morph_model.predict(processed, verbose=0)[0][0])\n",
        "        injury_conf = float(self.injury_model.predict(processed, verbose=0)[0][0])\n",
        "\n",
        "        return face_img, {\"morph\": morph_conf, \"injury\": injury_conf, \"face_detected\": True, \"bbox\": bbox}\n",
        "\n",
        "    def visualize_results(self, frame, results):\n",
        "        \"\"\"Draw analysis results on the frame\"\"\"\n",
        "        output_frame = frame.copy()\n",
        "\n",
        "        if not results[\"face_detected\"]:\n",
        "            cv2.putText(output_frame, \"No face detected\", (20, 40),\n",
        "                       self.font, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "            return output_frame\n",
        "\n",
        "        # Draw bounding box\n",
        "        x, y, w, h = results[\"bbox\"]\n",
        "        color = (0, 255, 0) if results[\"morph\"] < 0.5 else (0, 0, 255)\n",
        "        cv2.rectangle(output_frame, (x, y), (x+w, y+h), color, 2)\n",
        "\n",
        "        # Morphing result\n",
        "        morph_text = f\"Morph: {'ORIGINAL' if results['morph'] < 0.5 else 'MORPHED'} ({results['morph']*100:.1f}%)\"\n",
        "        cv2.putText(output_frame, morph_text, (x, y-10),\n",
        "                   self.font, 0.7, color, 2, cv2.LINE_AA)\n",
        "\n",
        "        # Injury detection\n",
        "        if results[\"injury\"] > 0.4:\n",
        "            injury_text = f\"Injury detected! ({results['injury']*100:.1f}%)\"\n",
        "            cv2.putText(output_frame, injury_text, (x, y+h+30),\n",
        "                       self.font, 0.7, (0, 165, 255), 2, cv2.LINE_AA)\n",
        "            cv2.rectangle(output_frame, (x, y), (x+w, y+h), (0, 165, 255), 3)\n",
        "\n",
        "        return output_frame\n",
        "\n",
        "def start_webcam():\n",
        "    \"\"\"Start webcam using JavaScript and process frames\"\"\"\n",
        "    analyzer = FaceAnalyzer()\n",
        "\n",
        "    js = Javascript('''\n",
        "    async function startWebcam() {\n",
        "        const div = document.createElement('div');\n",
        "        const video = document.createElement('video');\n",
        "        video.style.display = 'block';\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "        video.srcObject = stream;\n",
        "        await video.play();\n",
        "\n",
        "        // Resize the output to fit the video element.\n",
        "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "        return video;\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "    display(js)\n",
        "    video = eval_js('startWebcam()')\n",
        "\n",
        "    print(\"Webcam started. Press 'q' in the console to stop.\")\n",
        "\n",
        "    while True:\n",
        "        # Get frame from webcam\n",
        "        js_reply = eval_js('''\n",
        "        async function getFrame() {\n",
        "            const video = document.querySelector('video');\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            return canvas.toDataURL('image/jpeg', 0.8);\n",
        "        }\n",
        "        getFrame();\n",
        "        ''')\n",
        "\n",
        "        # Convert JavaScript frame to OpenCV image\n",
        "        header, encoded = js_reply.split(\",\", 1)\n",
        "        binary_data = base64.b64decode(encoded)\n",
        "        img = Image.open(BytesIO(binary_data))\n",
        "        frame = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Analyze frame\n",
        "        face_img, results = analyzer.analyze_frame(frame)\n",
        "        output_frame = analyzer.visualize_results(frame, results)\n",
        "\n",
        "        # Display results\n",
        "        clear_output(wait=True)\n",
        "        plt.imshow(cv2.cvtColor(output_frame, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # Check for quit command\n",
        "        user_input = input(\"Press 'q' and Enter to stop, or just Enter to continue: \")\n",
        "        if user_input.lower() == 'q':\n",
        "            break\n",
        "\n",
        "    print(\"Webcam stopped\")\n",
        "\n",
        "def analyze_uploaded_image():\n",
        "    \"\"\"Handle image upload and analysis\"\"\"\n",
        "    analyzer = FaceAnalyzer()\n",
        "\n",
        "    # Create file upload dialog\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        print(\"No file uploaded\")\n",
        "        return\n",
        "\n",
        "    filename = next(iter(uploaded.keys()))\n",
        "    img = cv2.imread(filename)\n",
        "\n",
        "    if img is None:\n",
        "        print(\"Error loading image\")\n",
        "        return\n",
        "\n",
        "    # Analyze image\n",
        "    face_img, results = analyzer.analyze_frame(img)\n",
        "    output_frame = analyzer.visualize_results(img, results)\n",
        "\n",
        "    # Display results\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.imshow(cv2.cvtColor(output_frame, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Add text summary\n",
        "    if results[\"face_detected\"]:\n",
        "        morph_status = \"ORIGINAL\" if results[\"morph\"] < 0.5 else \"MORPHED\"\n",
        "        injury_status = \"YES\" if results[\"injury\"] > 0.4 else \"NO\"\n",
        "\n",
        "        plt.title(f\"Analysis Results:\\n\\n\" +\n",
        "                 f\"Morph Status: {morph_status} ({results['morph']*100:.1f}%)\\n\" +\n",
        "                 f\"Injury Detected: {injury_status} ({results['injury']*100:.1f}%)\",\n",
        "                 pad=20, fontsize=12)\n",
        "    else:\n",
        "        plt.title(\"No face detected in image\", pad=20, fontsize=12)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Main UI\n",
        "display(HTML('''\n",
        "<div style=\"margin: 10px 0; padding: 10px; border-radius: 5px; background: #f5f5f5;\">\n",
        "    <h3 style=\"margin-top: 0;\">Face Analysis System</h3>\n",
        "    <button onclick=\"analyzeUploadedImage()\"\n",
        "            style=\"padding: 10px 20px; background-color: #4285F4; color: white; border: none; border-radius: 5px; cursor: pointer; margin-right: 10px;\">\n",
        "        📤 Upload Image\n",
        "    </button>\n",
        "    <button onclick=\"startWebcamAnalysis()\"\n",
        "            style=\"padding: 10px 20px; background-color: #EA4335; color: white; border: none; border-radius: 5px; cursor: pointer;\">\n",
        "        🎥 Live Webcam\n",
        "    </button>\n",
        "</div>\n",
        "\n",
        "<script>\n",
        "function analyzeUploadedImage() {\n",
        "    google.colab.kernel.invokeFunction('analyze_uploaded_image', []);\n",
        "}\n",
        "function startWebcamAnalysis() {\n",
        "    google.colab.kernel.invokeFunction('start_webcam', []);\n",
        "}\n",
        "</script>\n",
        "'''))\n",
        "\n",
        "# Register functions for Colab\n",
        "from google.colab import output\n",
        "output.register_callback('analyze_uploaded_image', analyze_uploaded_image)\n",
        "output.register_callback('start_webcam', start_webcam)"
      ],
      "metadata": {
        "id": "dB0gAPFaGTkL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}